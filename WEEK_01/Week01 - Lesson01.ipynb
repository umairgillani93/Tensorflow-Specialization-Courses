{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Time-Series:\n",
    "\n",
    "Time Series is making predictions off of the __Data__ which is in sequential form. For instance, we want to predict a __Stalk Prices__ and __Weather__ based on previous time values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Time-Series:\n",
    "\n",
    "Time Series could be off many types. Some of them follow some sort of pattern and some are completely random. \n",
    "Let's dicsuss a few of those.\n",
    "\n",
    "* __Trend Following__: In this time-series we have data points that follow some sort of __Trend__. For instance an inclinde straight line. \n",
    "\n",
    "\n",
    "* __Sessionality__: It's the time-series which follow some sort of repeated intervels. For instance, consider the example of passengers travelling to different countries - During vacations session, the flights increse and vice-versa following some sessional condition. \n",
    "\n",
    "\n",
    "* __Auto-correlation__: In this type of time-series we don't have any __Trend__ or __Sessionality__ but we still have some sort of pattern following. For examples, during each raising spike we have some lagging series of values. It Auto-correlates with the delayed copy of itself. We can have __Multiple__ Auto-correlations in a single time-series i.e Series of lagging factors and differenct thresholds following bike a spike\n",
    "\n",
    "* __Non-Stationary__: This type of time-series follows exact same pattern for some specific __Threshold__ but after that becomes completely random. Mostly in real-life, we have this type of Time-Series available for our analysis \n",
    "\n",
    "__Time-Series__ we have in our daily lives, follows a bit of each such pattern i.e __Trend + Sessionality + Auto-Correlation + Noise__. Off of that data, we can spot the patterns, and following __Machine Learning__ on this sort of sequential data, we can come up with future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputed-Data:\n",
    "\n",
    "ormally we have values missing in our sequential data. This can decrease the performance of our model. So, what we can do is to __Impute__ the data, i.e fill-up those empty values with some sort of data. This data is taken from previous values that what pattern our data followed, and on the basis of that we impute the gaps with some __mean/average__ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
